# -*- coding: utf-8 -*-
import scrapy
from shiyanlouhub.items import ShiyanlouhubItem


class RespositoriesSpider(scrapy.Spider):
    name = 'respositories'
#    allowed_domains = ['https://github.com/shiyanlou?tab=repositories']
    @property
    def start_urls(self):
                        
        url_tmpl ='https://github.com/shiyanlou?page={}&tab=repositories'
        return (url_tmpl.format(i) for i in range(1,5))

    def parse(self,response):
        for i in response.css('li.public'):
            '''
            item = ShiyanlouhubItem({
                'name': i.xpath('.//h3/a/text()').re('\w.*'),
               'datetime': i.xpath('.//relative-time/@datetime').extract()
               
                                                                                              })   
            yield item
            '''
            item = ShiyanlouhubItem
            item['name'] = i.xpath('.//h3/a/text()').re('\w.*'),
            item['datetime'] = i.xpath('.//relative-time/@datetime').extract()
            href_next = response.urljoin(i.xpath('.//h3/a/@href').extract_first()
            request = scrapy.Responst(href_next,callback=self.parse_next)
            request.meta['item']=item
            yield request
    def parse_next(self,response):
        item = response.meta['item']
        item['commits']=response.css('(//span[@class="num text-emphasized"])[1]/text()').re_first('[^\d]*(\d*)[^\d]')
        item['branches']=response.css('(//span[@class="num text-emphasized"])[2]/text()').re_first('[^\d]*(\d*)[^\d]')
        
        item['releases']=response.css('(//span[@class="num text-emphasized"])[3]/text()').re_first('[^\d]*(\d*)[^\d]')
        yield item


